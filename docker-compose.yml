services:
  ollama:
    image: ollama/ollama:latest
    container_name: ollama
    ports:
      - "${OLLAMA_PORT:-11434}:11434"
    volumes:
      - ollama_data:/root/.ollama
    restart: unless-stopped
    networks:
      - backend
    healthcheck:
      test:
        [
          "CMD",
          "sh",
          "-lc",
          "wget -qO- http://127.0.0.1:11434/api/tags >/dev/null 2>&1 || exit 1",
        ]
      interval: 10s
      timeout: 3s
      retries: 10

  n8n:
    image: n8nio/n8n:latest
    container_name: n8n
    ports:
      - "${N8N_PORT:-5678}:5678"
    volumes:
      - n8n_data:/home/node/.n8n
    environment:
      - N8N_PORT=5678
      - N8N_PROTOCOL=${N8N_PROTOCOL:-http}
      - N8N_HOST=${N8N_HOST:-localhost}
      - WEBHOOK_URL=${WEBHOOK_URL:-http://localhost:5678/}
      # If calling ollana w and http request,
      # use http://ollama:11434
    depends_on:
      - ollama
    restart: unless-stopped
    networks:
      - backend

  mcp:
    build:
      context: .
      dockerfile: Dockerfile.mcp
    container_name: mcp
    environment:
      - MCP_TRANSPORT=http
      - MCP_DB_PATH=/data/mcp_demo.sqlite
      - LOG_LEVEL=INFO
      # Optional: expose a port used by FastMCP's HTTP transport
      - MCP_HTTP_HOST=0.0.0.0
      - MCP_HTTP_PORT=8000
      # when calling from n8n
      # use http://mcp:8000
    ports:
      - "${MCP_PORT:-8000}:8000"
    volumes:
      # Your generated artifacts
      - ./data:/data
      # If you want the server to access RAG files later:
      - ./documents:/documents:ro
      - ./docs:/docs:ro
    restart: unless-stopped
    networks: [backend]
    depends_on:
      - ollama

networks:
  backend:

volumes:
  n8n_data:
  ollama_data:
